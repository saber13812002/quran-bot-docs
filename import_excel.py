import pandas as pd
import os
import requests
from urllib.parse import urljoin
import json

def read_excel_data(file_path):
    # Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² ÙØ§ÛŒÙ„ Ø§Ú©Ø³Ù„
    xls = pd.ExcelFile(file_path)
    
    # Ø®ÙˆØ§Ù†Ø¯Ù† Ù‡Ø± Ø´ÛŒØª Ø¨Ù‡ ØµÙˆØ±Øª Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ
    sheets_data = {}
    for sheet_name in xls.sheet_names:
        sheets_data[sheet_name] = pd.read_excel(xls, sheet_name=sheet_name)
    
    return sheets_data

def print_data(data):
    for sheet, df in data.items():
        print(f"Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø´ÛŒØª {sheet}:")
        print(df.head(300)) 


def create_folder_with_meta_json(save_directory, english_name, persian_name):
    base_folder = os.path.join(save_directory, english_name)

    print(english_name)
    if not os.path.exists(english_name):
        os.makedirs(english_name)
        print(f"ğŸ“ Ù¾ÙˆØ´Ù‡ '{english_name}' Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯.")
    else:
        print(f"ğŸ“ Ù¾ÙˆØ´Ù‡ '{english_name}' Ù‚Ø¨Ù„Ø§Ù‹ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯.")

    meta_file_path = os.path.join(save_directory, english_name, '_meta.json')
    print(meta_file_path)
    if not os.path.exists(meta_file_path):
        meta_content = {
            english_name: persian_name
        }
        
        with open(meta_file_path, 'w', encoding='utf-8') as meta_file:
            json.dump(meta_content, meta_file, ensure_ascii=False, indent=4)
        print(f"ğŸ“„ ÙØ§ÛŒÙ„ '_meta.json' Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯: {meta_file_path}")
    else:
        print("ğŸ“ ÙØ§ÛŒÙ„ '_meta.json' Ù‚Ø¨Ù„Ø§Ù‹ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯.")
    # os.makedirs(base_folder, exist_ok=True)    

def throw(near_folder):
    raise near_folder
# main

if __name__ == "__main__":
    file_path = 'Table Of Contents.report.xlsx'
    data = read_excel_data(file_path)
    # print_data(data)

    save_directory = r"D:\saberprojects\kasra\kasra-docs\pages"
    static_img_dir = r"D:\saberprojects\kasra\kasra-docs\public\img"
    static_assets_dir = r"D:\saberprojects\kasra\kasra-docs\public\assets"
    # Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡ Ú©Ø³Ø±Ø§ Ø¯Ø± Ø¯Ø§ÛŒØ±Ú©ØªÙˆØ±ÛŒ Ø°Ø®ÛŒØ±Ù‡
    # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ù¾ÙˆØ´Ù‡ Ú©Ø³Ø±Ø§
    name_english = "kasra"
    name_persian= "Ú©Ø³Ø±Ø§";
    create_folder_with_meta_json(save_directory,name_english,name_persian)

    save_directory_v1 = os.path.join(save_directory, 'kasra')
    name_english_v1 = "v1"
    name_persian_v1 = "Ù†Ø³Ù„ Ø¯ÙˆÙ…";
    create_folder_with_meta_json(save_directory_v1,name_english_v1,name_persian_v1)


    # Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² Ø´ÛŒØª Ø§ÙˆÙ„ Ùˆ Ø³ÙˆÙ…
    first_sheet_data = data['v1']
    third_sheet_data = data['extracted_links']

    for index, row in first_sheet_data.iterrows():
        title = row['Title']
        reference = row['Reference']
        perian_type = row['Perian Type']
        hidden = row['Hidden']

        # Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø± third_sheet_data Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² index
        if index < len(third_sheet_data):
            near_folder = third_sheet_data.iloc[index]['nearFolder']
            full_url = third_sheet_data.iloc[index]['full_url']
            filename1 = third_sheet_data.iloc[index]['filename1']
            filename2 = third_sheet_data.iloc[index]['filename2']
            htm_name = third_sheet_data.iloc[index]['htmName']

            # Ø§ÛŒÙ†Ø¬Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ú©Ø§Ø± Ú©Ù†ÛŒØ¯
            print(f"Ø¹Ù†ÙˆØ§Ù†: {title}, Ù…Ø±Ø¬Ø¹: {reference}, Ù†ÙˆØ¹: {perian_type}, Ù¾Ù†Ù‡Ø§Ù†: {hidden}, Ù¾ÙˆØ´Ù‡ Ù†Ø²Ø¯ÛŒÚ©: {near_folder}, URL Ú©Ø§Ù…Ù„: {full_url}, Ù†Ø§Ù… ÙØ§ÛŒÙ„ 1: {filename1}, Ù†Ø§Ù… ÙØ§ÛŒÙ„ 2: {filename2}, Ù†Ø§Ù… HTML: {htm_name}")

    

    # # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ nearFolder Ø¯Ø± Ø³ØªÙˆÙ† htmName Ø´ÛŒØª Ø³ÙˆÙ…
    # if any(third_sheet_data['htmName'] == near_folder):
    #     # Ø¯Ø§Ù†Ù„ÙˆØ¯ ÙØ§ÛŒÙ„ HTML
    #     html_url = first_sheet_data.iloc[0]['htmlUrl']  # ÙØ±Ø¶ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ú©Ù‡ Ø¢Ø¯Ø±Ø³ HTML Ø¯Ø± Ø´ÛŒØª Ø§ÙˆÙ„ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø³Øª
    #     html_file_path = os.path.join(base_folder, f"{near_folder}.html")
        
    #     response = requests.get(html_url)
    #     with open(html_file_path, 'wb') as html_file:
    #         html_file.write(response.content)
    #     print(f"ğŸ“„ ÙØ§ÛŒÙ„ HTML Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯: {html_file_path}")

    #     # Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯ÛŒØ§Ù‡Ø§
    #     media_urls = first_sheet_data.iloc[0]['mediaUrls'].split(',')  # ÙØ±Ø¶ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ… Ú©Ù‡ Ø¢Ø¯Ø±Ø³â€ŒÙ‡Ø§ÛŒ Ù…Ø¯ÛŒØ§ Ø¯Ø± ÛŒÚ© Ø³ØªÙˆÙ† Ø¨Ù‡ ØµÙˆØ±Øª Ú©Ø§Ù…Ø§ Ø¬Ø¯Ø§ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯
    #     media_folder = os.path.join(static_img_folder, 'media')
    #     os.makedirs(media_folder, exist_ok=True)

    #     for media_url in media_urls:
    #         media_response = requests.get(media_url.strip())
    #         media_file_name = os.path.basename(media_url.strip())
    #         media_file_path = os.path.join(media_folder, media_file_name)
    #         with open(media_file_path, 'wb') as media_file:
    #             media_file.write(media_response.content)
    #         print(f"ğŸ“¦ Ù…Ø¯ÛŒØ§ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´Ø¯: {media_file_path}")
    # else:
    #     print("âŒ Ù‡ÛŒÚ† Ù…ÙˆØ±Ø¯ÛŒ Ø¨Ø§ nearFolder Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯.")












